<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Holden Lee's Website</title>
    <link href="http://holdenlee.github.io/atom.xml" rel="self" />
    <link href="http://holdenlee.github.io" />
    <id>http://holdenlee.github.io/atom.xml</id>
    <author>
        <name>Holden Lee</name>
        <email>oldheneel@gmail.com</email>
    </author>
    <updated>2018-04-20T00:00:00Z</updated>
    <entry>
    <title>toki pona</title>
    <link href="http://holdenlee.github.io/toki%20pona.html" />
    <id>http://holdenlee.github.io/toki%20pona.html</id>
    <published>2018-04-20T00:00:00Z</published>
    <updated>2018-04-20T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">

  <div id="content">
    <div class="page header">
      <h1> toki pona </h1>
    </div>
    
    
    <div class="info">
      
       
        <p>Posted: 2018-04-20 
          , Modified: 2018-04-20 
	</p>
      
       <p>Tags: <a href="/tags/language.html">language</a>, <a href="/tags/conlang.html">conlang</a>, <a href="/tags/Splash.html">Splash</a></p> 
       <p>Parent: <a href="/Topics.html">Topics</a></p> 
	   <p>Children: </p> 
    </div>
    
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>Shortlink to this page: http://tiny.cc/hltp</p>
<p>Resources for Splash class:</p>
<ul>
<li><a href="http://tokipona.net/tp/default.aspx">tokipona.net</a></li>
<li><a href="http://tokipona.net/tp/janpije/okamasona.php">jan Pije’s lessons</a></li>
<li>Presentation in <a href="https://www.dropbox.com/s/nic1hqcmzbi60uy/tokipona.pptx?dl=0">pptx</a>.</li>
<li><a href="http://tokipona.net/tp/ClassicWordList.aspx">word list</a>, <a href="https://www.dropbox.com/s/lq0rbdjlb1ck0sn/tokipona.xlsx?dl=0">xlsx</a></li>
</ul>

  </div>
  
    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
  
</div>
]]></summary>
</entry>
<entry>
    <title>Esperanto</title>
    <link href="http://holdenlee.github.io/Esperanto.html" />
    <id>http://holdenlee.github.io/Esperanto.html</id>
    <published>2018-04-20T00:00:00Z</published>
    <updated>2018-04-20T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">

  <div id="content">
    <div class="page header">
      <h1> Esperanto </h1>
    </div>
    
    
    <div class="info">
      
       
        <p>Posted: 2018-04-20 
          , Modified: 2018-04-20 
	</p>
      
       <p>Tags: <a href="/tags/Esperanto.html">Esperanto</a>, <a href="/tags/language.html">language</a>, <a href="/tags/conlang.html">conlang</a>, <a href="/tags/Splash.html">Splash</a></p> 
       <p>Parent: <a href="/Topics.html">Topics</a></p> 
	   <p>Children: </p> 
    </div>
    
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>Shortlink to this page: http://tiny.cc/hlesp</p>
<p>Resources for Splash class:</p>
<ul>
<li>Presentation in <a href="https://www.dropbox.com/s/8aeqct22vldl8uv/Esperanto_Splash_2018.pptx?dl=0">pptx</a>. Contains links to resources.</li>
<li><a href="https://docs.google.com/document/d/1Q2CtDmoEteti4ZhXosaZy19gqnMB-Ce_3yWpTw5qHm4/edit?usp=sharing">Transcript</a></li>
<li><a href="https://docs.google.com/document/d/1PGMGvlyAsRKfpRoTSvH-a_KHz1d6sY5GLxs9RALqWJg/edit?usp=sharing">Cheat sheet</a></li>
</ul>

  </div>
  
    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
  
</div>
]]></summary>
</entry>
<entry>
    <title>Simulated tempering Langevin Monte Carlo</title>
    <link href="http://holdenlee.github.io/Simulated%20tempering%20Langevin%20Monte%20Carlo.html" />
    <id>http://holdenlee.github.io/Simulated%20tempering%20Langevin%20Monte%20Carlo.html</id>
    <published>2017-11-26T00:00:00Z</published>
    <updated>2017-11-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">

  <div id="content">
    <div class="page header">
      <h1> Simulated tempering Langevin Monte Carlo </h1>
    </div>
    
    
    <div class="info">
       <div class="subtitle"><p>Rong Ge, Holden Lee, Andrej Risteski</p></div> 
       
        <p>Posted: 2017-11-26 
          , Modified: 2017-11-26 
	</p>
      
       <p>Tags: <a href="/tags/math.html">math</a></p> 
       <p>Parent: <a href="/Research.html">Research</a></p> 
	   <p>Children: </p> 
    </div>
    
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#basic-information">Basic information</a><ul>
 <li><a href="#abstract">Abstract</a></li>
 </ul></li>
 <li><a href="#blog-post">Blog post</a></li>
 <li><a href="#cartoon">Cartoon</a></li>
 <li><a href="#problem">Problem</a></li>
 <li><a href="#introduction">Introduction</a><ul>
 <li><a href="#optimization-vs.sampling">Optimization vs. sampling</a><ul>
 <li><a href="#the-great-divide-of-optimization">The great divide of optimization</a></li>
 <li><a href="#the-great-divide-of-sampling">The great divide of sampling</a></li>
 </ul></li>
 <li><a href="#why-optimizers-care-about-sampling">Why optimizers care about sampling</a></li>
 </ul></li>
 <li><a href="#main-result">Main result</a><ul>
 <li><a href="#algorithm">Algorithm</a><ul>
 <li><a href="#langevin-diffusion">Langevin diffusion</a></li>
 <li><a href="#simulated-tempering-turns-the-heat-on">Simulated tempering turns the heat on</a></li>
 <li><a href="#combining-langevin-diffusion-and-simulated-tempering">Combining Langevin diffusion and simulated tempering</a></li>
 </ul></li>
 </ul></li>
 <li><a href="#proof-sketch">Proof sketch</a><ul>
 <li><a href="#markov-chain-decomposition-theorem">Markov chain decomposition theorem</a><ul>
 <li><a href="#previous-decomposition-theorems">Previous decomposition theorems</a></li>
 <li><a href="#decomposition-theorem-with-sets">Decomposition theorem with sets</a></li>
 <li><a href="#applying-the-decomposition-theorem">Applying the decomposition theorem</a></li>
 <li><a href="#simulated-tempering-mixes-for-p">Simulated tempering mixes for <span class="math inline"><em>p</em></span></a></li>
 </ul></li>
 </ul></li>
 <li><a href="#takeaways">Takeaways</a></li>
 <li><a href="#further-directions">Further directions</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="basic-information">Basic information</h2>
<p>This page is about the following paper:</p>
<blockquote>
<p>Ge, R., Lee, H., &amp; Risteski, A. (2017). <strong>Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo.</strong> NIPS AABI workshop 2017. arXiv preprint arXiv:1710.02736.</p>
</blockquote>
<p>Shortlink: <a href="http://tiny.cc/glr17">tiny.cc/glr17</a></p>
<ul>
<li><a href="https://arxiv.org/abs/1710.02736">arXiv</a>, <a href="https://arxiv.org/pdf/1710.02736.pdf">pdf</a>.</li>
<li><a href="https://www.dropbox.com/s/v2pijnsk9c6t11s/soft_partition2.pdf?dl=0">Supplement</a>: Contains a simpler proof of the main theorem in the paper. I recommend reading this instead of the proof in the paper. Note this is a work in progress.</li>
<li><a href="https://www.dropbox.com/s/44udkqyd2r95qzk/slides_IAS.pdf?dl=0">Slides</a>, <a href="https://dynalist.io/d/wW7edPHuU41y1qxWAI0fL__c#z=c2y7iGMb-rjqoGupMLQ1DAWe">transcript</a></li>
<li><a href="https://www.dropbox.com/s/nvh4g055lyx9yth/poster_bayesian.pdf?dl=0">Poster</a></li>
</ul>
<h3 id="abstract">Abstract</h3>
<p>A key task in Bayesian statistics is sampling from distributions that are only specified up to a partition function (i.e., constant of proportionality). However, without any assumptions, sampling (even approximately) can be #P-hard, and few works have provided “beyond worst-case” guarantees for such settings.</p>
<p>For log-concave distributions, classical results going back to Bakry and Emery (1985) show that natural continuous-time Markov chains called Langevin diffusions mix in polynomial time. The most salient feature of log-concavity violated in practice is uni-modality: commonly, the distributions we wish to sample from are multi-modal. In the presence of multiple deep and well-separated modes, Langevin diffusion suffers from torpid mixing.</p>
<p>We address this problem by combining Langevin diffusion with simulated tempering. The result is a Markov chain that mixes more rapidly by transitioning between different temperatures of the distribution. We analyze this Markov chain for the canonical multi-modal distribution: a mixture of gaussians (of equal variance). The algorithm based on our Markov chain provably samples from distributions that are close to mixtures of gaussians, given access to the gradient of the log-pdf.</p>
<!-- 
TITLE: Sampling from multimodal distributions by changing the temperature

In this post I describe recent work with Rong Ge and Andrej Risteski on an algorithm that provably samples from certain multimodal distributions. 

Sampling is a fundamental task in Bayesian statistics, and dealing with multimodal distributions is a core challenge. 
One common technique to sample from a probability distribution is to define a Markov chain with that distribution as its stationary distribution. This general approach is called **Markov chain Monte Carlo**. However, in many practical problems, the Markov chain does not mix rapidly, and we obtain samples from only one part of the distribution.

Practitioners have dealt with this problem through heuristics involving temperature. However, there has been little theoretical analysis of such methods. In our paper, we give provable guarantees for a temperature-based method called simulated tempering when it is set up correctly with the base Markov chain, called Langevin diffusion.
-->
<h2 id="blog-post">Blog post</h2>
<p>In this post I describe recent work with Rong Ge and Andrej Risteski on an algorithm that provably samples from certain multimodal distributions.</p>
<p>Sampling is a fundamental task in Bayesian statistics, and dealing with multimodal distributions is a core challenge. One common technique to sample from a probability distribution is to define a Markov chain with that distribution as its stationary distribution. This general approach is called <strong>Markov chain Monte Carlo</strong>. However, in many practical problems, the Markov chain does not mix rapidly, and we obtain samples from only one part of the distribution.</p>
<p>Practitioners have dealt with this problem through heuristics involving temperature. However, there has been little theoretical analysis of such methods. In our paper, we give provable guarantees for a temperature-based method called simulated tempering when it is set up correctly with the base Markov chain, called Langevin diffusion.</p>
<p>Here is a cartoon of our results:</p>
<h2 id="cartoon">Cartoon</h2>
<center>
<img src="pics/not_mixing.png" width="50%" height="50%">
</center>
<p>A Markov chain with local moves such as Langevin diffusion gets stuck in a local mode.</p>
<center>
<img src="pics/mixing.png" width="50%" height="50%">
</center>
<p>Creating a meta-Markov chain which <em>changes the temperature</em> can exponentially speed up mixing.</p>
<h2 id="problem">Problem</h2>
<p>The concrete problem we address is the following.</p>
<blockquote>
<p>Sample from a probability distribution <span class="math inline">\(p(x) \propto e^{-f(x)}\)</span>, <span class="math inline">\(x\in \R^d\)</span> given access to <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(\nabla f(x)\)</span>.</p>
</blockquote>
<p>We can’t hope to solve this problem in full generality<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, but we can hope to find methods that work for a wider class of distributions, including some multimodal distributions.</p>
<h2 id="introduction">Introduction</h2>
<p>First I give some background for the problem.</p>
<!--
* I'll introduce the problem of sampling, a fundamental task of Bayesian statistics. -->
<ul>
<li>I’ll explain the analogy between sampling and optimization, in particular how going beyond <em>convexity</em> in optimization is like going beyond <em>log-concavity</em> in sampling.</li>
<li>I’ll describe some connections between sampling and optimization, hopefully motivating people who work in optimization to care about sampling.</li>
</ul>
<!-- ## The problem of sampling-->
<h3 id="optimization-vs.sampling">Optimization vs. sampling</h3>
<h4 id="the-great-divide-of-optimization">The great divide of optimization</h4>
<p>The goal in optimization is to find the minimum of a function <span class="math inline">\(f\)</span>.</p>
<p>When <span class="math inline">\(f\)</span> is <strong>convex</strong>, this is well-understood:</p>
<ul>
<li>There is a unique local minimum, which is a global minimum.</li>
<li>This allows local search algorithms such as <strong>gradient descent</strong> (as well as a whole extended family of zero, first, and second order algorithms) to work.</li>
<li>Well-established mathematics characterizes how fast we can optimize convex functions based on various properties.</li>
</ul>
<p>On the other hand, when <span class="math inline">\(f\)</span> is non-convex,</p>
<ul>
<li>There can be many bad local minima.</li>
<li>Gradient descent can get trapped in those local minima.</li>
<li>The problem is NP-hard in the worst-case. This is a barrier for theoreticians as it means we won’t have clean, beautiful, assumption-free results, and we’ll have to get our hands dirty.</li>
<li>Still, gradient descent-like algorithms often still well in practice.</li>
</ul>
<p>This is the “great divide” in optimization. On one side we have the well-understood area of convex optimization, and on the other we lump everything under the label “non-convex”. We care about non-convex optimization because many practical optimization problems (such as those arising in machine learning, and deep learning in particular) are very non-convex. In light of the worst-case results we’ll have to get our hands dirty and see what is the structure of real-world problems that allow us to do nonconvex optimization, to close the gap between theory and practice.</p>
<h4 id="the-great-divide-of-sampling">The great divide of sampling</h4>
<p>Analogously we have a “great divide” in sampling.</p>
<p>Recall that we want to sample from <span class="math inline">\(p(x)\propto e^{-f(x)}\)</span> where <span class="math inline">\(x\in \R^d\)</span>. When <span class="math inline">\(f\)</span> is convex, i.e. <span class="math inline">\(p\)</span> is <strong>log-concave</strong>, this is well-understood.</p>
<ul>
<li><span class="math inline">\(f\)</span> has a unique local minimum, which means the distribution <span class="math inline">\(p\)</span> is unimodal.</li>
<li>There is a natural algorithm (a Markov chain) called <strong>Langevin diffusion</strong> - which is basically gradient descent plus gaussian noise - that works, and a lot of beautiful math that goes into the analysis.</li>
</ul>
<p>On the other hand, when <span class="math inline">\(f\)</span> is non-convex,</p>
<ul>
<li><span class="math inline">\(p\)</span> can be multimodal</li>
<li>Langevin diffusion can take exponentially long to mix, because it gets trapped in one of the modes.</li>
<li>The problem is #P-hard in the worst case.</li>
<li>Sampling algorithms can still do well in practice, sometimes with the aid of heuristics such as temperature-based methods.</li>
</ul>
<p>We care about this difficult case because modern sampling problems (such as those arising in Bayesian machine learning) are often non-log-concave. Like in nonconvex optimization, we must go beyond worst case analysis, and find what kind of structure in non-log-concave distributions allows us to sample efficiently.</p>
<p>Note that log-concavity makes sense for sampling problems on <span class="math inline">\(\R^d\)</span>, but there are other conditions that similarly give guarantees for mixing, such as <strong>correlation decay</strong> for problems in <span class="math inline">\(\{0,1\}^d\)</span>. As is the case for log-concavity, we have provable guarantees for problems satisfying correlation decay, and beyond it, the field is murkier.</p>
<h3 id="why-optimizers-care-about-sampling">Why optimizers care about sampling</h3>
<p>The primary connection between optimization and sampling is the following: if we sample from <span class="math inline">\(e^{-f}\)</span>, we’re more likely to get points where <span class="math inline">\(f\)</span> is small. We can take this to the extreme: In the limit as <span class="math inline">\(\beta \to \infty\)</span>, the distribution <span class="math inline">\(e^{-\beta f}\)</span> is peaked at exactly the global minima. <span class="math inline">\(\beta\)</span> is called the inverse temperature (<span class="math inline">\(\beta=\frac 1T\)</span>) in statistical physics.</p>
<p>So in a sense, optimization is “just” a sampling problem. In reality, however, we can’t usually take <span class="math inline">\(\beta\to \infty\)</span>, so there is tradeoff between ability to sample and quality of the solution.</p>
<p>Here is a list of past work connecting optimization and sampling, or more generally, using randomness:</p>
<ul>
<li>To escape local minima, we can add noise to gradient descent (which is exactly Langevin diffusion), at the cost of not exactly getting a minimum. This has been analyzed in, for example, <a href="https://arxiv.org/abs/1702.05575">A hitting time analysis of stochastic gradient langevin dynamics</a>. <a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> <!--[ZLC17]--></li>
<li>Several works have heuristically explained the success of stochastic gradient descent using Langevin dynamics: if we pretend the noise from the stochasticity is gaussian, then we get exactly Langevin dynamics and the ability to escape local minima. <!--[WT11], [MHB16]--> The noise can also be thought of as imposing a prior, helping generalization.<br />
</li>
<li>Langevin dynamics has also inspired temperature-based methods such as <a href="https://arxiv.org/abs/1611.01838">entropy-SGD for optimizing neural networks</a>. <!-- [YZM17], [CCSLBBCSZ17]--></li>
<li>Other works on non-convex optimization also use the idea of randomness, for example, adding perturbations to help escape saddle points. <!--[AG16, GJNKJ17]--> See <a href="http://www.offconvex.org/2017/07/19/saddle-efficiency/">post</a>.</li>
<li>Another connection to note is a work by Jake Abernathy and Elad Hazan connecting the interior point methods (following the central path) to simulated annealing for convex optimization. <!--[AH15]--> See <a href="http://www.minimizingregret.com/2016/03/the-two-cultures-of-optimization.html">post</a>.</li>
</ul>
<h2 id="main-result">Main result</h2>
<p>We analyze a natural algorithm for sampling beyond log-concavity, combining Langevin diffusion with simulated tempering. We show efficient sampling given a structural assumption on the distribution, that it is close to a mixture of gaussians with polynomially many components.</p>
<p>Our main theorem is the following.</p>
<blockquote>
<p><strong>Theorem</strong>: Let <span class="math inline">\(p(x)\propto e^{-f(x)}\)</span> be a mixture of gaussians, i.e., <span class="math display">\[f(x)=-\ln\pa{\sumo in w_i e^{-\fc{\ve{x-\mu_j}^2}{2\si^2}}}\]</span>. Suppose we can query <span class="math inline">\(f(x)\)</span>, <span class="math inline">\(\nb f(x)\)</span>, and <span class="math inline">\(\si, \ve{\mu_j}\le D\)</span>. There is an algorithm (based on Langevin diffusion and simulated tempering), which runs in time <span class="math inline">\(\poly(1/w_{\min},1/\si^2,1/\ep,d,D)\)</span> that samples from a distribution <span class="math inline">\(\wt p\)</span> with <span class="math inline">\(\ve{p-\wt p}_1\le \ep\)</span>.</p>
</blockquote>
<p>Moreover, this theorem is robust in the following sense: if <span class="math inline">\(f\)</span> is only <span class="math inline">\(\De\)</span>-close in <span class="math inline">\(L^{\iy}\)</span> distance to a mixture of gaussians, then we incur an additional factor of <span class="math inline">\(\poly(e^{\De})\)</span> in complexity.</p>
<h3 id="algorithm">Algorithm</h3>
<p>The two algorithmic tools are</p>
<ol type="1">
<li><strong>Langevin diffusion</strong>, which is a generic chain for sampling given gradient access to log-pdf of distribution, and</li>
<li><strong>Simulated tempering</strong>, a heuristic for speeding up Markov Chains on multimodal distributions.</li>
</ol>
<h4 id="langevin-diffusion">Langevin diffusion</h4>
<p>Langevin is a continuous time random-walk for sampling from <span class="math inline">\(p\propto e^{-f}\)</span>, given access to the gradient of the log-pdf, <span class="math inline">\(f\)</span>. It is gradient flow plus Brownian motion, and described by a stochastic differential equation <span class="math display">\[dx_t = -\be_t \nb f(x_t)dt + \sqrt 2 d W_t.\]</span> It’s not necessary to understand the stochastic calculus: you can think of this as the limit of a discrete process, just as gradient flow is the continuous limit of gradient descent. The <span class="math inline">\(\eta\)</span>-discretized version is where we take a gradient step, with step size <span class="math inline">\(\eta\)</span>, and add gaussian noise scaled by <span class="math inline">\(\sqrt{2\eta}\)</span>:<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> <span class="math display">\[x_{t+\eta}=x_t-\eta \nb f(x_t) + \sqrt{2\eta}\xi_t.\]</span></p>
<p>Langevin diffusion has been well-studied, both in the math and CS communities. It is a classical result that the stationary distribution is proportional to <span class="math inline">\(e^{-f(x)}\)</span>. Bakry and Emery showed in the 80’s that if <span class="math inline">\(p\)</span> is <span class="math inline">\(\alpha\)</span>-log-concave, then the mixing time is on the order of <span class="math inline">\(\frac 1{\alpha}\)</span>.</p>
<p>With the recent algorithmic interest in Langevin diffusion, we want similar guarantees for discretized chain - that it converges to a measure close to <span class="math inline">\(p\)</span>. This was done by Dalalyan and Durmus and Moulines, and by Bubeck, Eldan, and Lehec, who also considered restriction to a convex set. For general distributions <span class="math inline">\(p\)</span> with some regularity conditions, Raginsky, Rakhlin, and Telgarsky showed that there is convergence to <span class="math inline">\(p\)</span> in time comparable to continuous dynamics.</p>
<p><em>So why can’t we just run Langevin dynamics?</em></p>
<p>Consider the example of well-separated gaussians. Bovier showed, via the theory of metastable processes, that transitioning from one peak to another takes exponential time. Roughly speaking, to estimate the expected time to travel from one mode to the other, consider paths between those modes. The time will be inversely proportional to the largest possible minimum probability on one of those paths.</p>
<p>If two gaussians with unit variance have means separated by <span class="math inline">\(2r\)</span>, then any path between them will pass through a point with probability less than <span class="math inline">\(e^{-r^2}\)</span>, so it will take on the order of <span class="math inline">\(e^{r^2}\)</span> time to move between the gaussians. Think of this as a “energy barrier” Langevin diffusion has to cross. Even if <span class="math inline">\(r\)</span> is as small as <span class="math inline">\(\log d\)</span>, the time will be superpolynomial in <span class="math inline">\(d\)</span>.</p>
<center>
<img src="pics/separated2.png">
</center>
<h4 id="simulated-tempering-turns-the-heat-on">Simulated tempering turns the heat on</h4>
<p>A key observation is that Langevin corresponding to a higher temperature distribution (with <span class="math inline">\(\beta f\)</span> rather than <span class="math inline">\(f\)</span>, where <span class="math inline">\(\beta&lt;1\)</span>) mixes faster. A high temperature flattens out the distribution.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>However, we can’t simply run Langevin at a higher temperature because the stationary distribution is wrong. The idea behind simulated tempering is to combine Markov chains at different temperatures, sometimes swapping to another temperature to help lower-temperature chains explore.</p>
<p>We can define simulated tempering with respect to any sequence of Markov chains <span class="math inline">\(M_i\)</span> on the same space. Think of <span class="math inline">\(M_i\)</span> as the Markov chain corresponding to temperature <span class="math inline">\(i\)</span>, with stationary distribution.</p>
<p>Then we define the simulated tempering Markov chain as follows.</p>
<ul>
<li>The <em>state space</em> is <span class="math inline">\(L\)</span> copies of the state space (in our case <span class="math inline">\(\mathbb R^d\)</span>), one copy for each temperature.</li>
<li>The evolution is defined as follows.
<ul>
<li>If the current point is <span class="math inline">\((i,x)\)</span>, then evolve according to the <span class="math inline">\(i\)</span>th chain <span class="math inline">\(M_i\)</span>.</li>
<li>Propose swaps with some rate <span class="math inline">\(\lambda\)</span>.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> When a swap is proposed, attempt to move to a neighboring chain, <span class="math inline">\(i'=i\pm 1\)</span>. With probability <span class="math inline">\(\min\{p_{i'}(x)/p_i(x), 1\}\)</span>, the transition is successful. Otherwise, stay at the same point. This is a <strong>Metropolis-Hastings step</strong>; its purpose is to preserves the stationary distribution.</li>
</ul></li>
</ul>
<p>It’s not too hard to see that the stationary distribution is the mixture distribution, i.e., <span class="math inline">\(p(i,x) = \rc L p_i(x)\)</span>. Simulated tempering is popular in practice along with other temperature-based methods such as simulated annealing, parallel tempering, (reverse) annealed importance sampling, and particle filters. Zheng and Woodard, Schmidler, and Huber gave decomposition results; however in our setting their bound on mixing is exponential in the number of gaussians.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></p>
<h4 id="combining-langevin-diffusion-and-simulated-tempering">Combining Langevin diffusion and simulated tempering</h4>
<p>Our algorithm is the following. Assume <span class="math inline">\(\sigma=1\)</span> for simplicity.</p>
<p>Take a sequence of betas starting from <span class="math inline">\(1/D^2\)</span>, going up by factors of <span class="math inline">\(1+1/d\)</span> (where <span class="math inline">\(d\)</span> is the ambient dimension) up to 1 and run simulated tempering for Langevin on these temperatures, suitably discretized. Take the samples that are at the <span class="math inline">\(L\)</span>th temperature.</p>
<center>
<img src="pics/stl.png" width="50%" height="50%">
</center>
<h2 id="proof-sketch">Proof sketch</h2>
<p>There are four main steps in the proof.</p>
<ol type="1">
<li>Prove a Markov chain decomposition theorem for distributions, that upper-bounds the mixing time. For discrete/continuous-time Markov chains, this is equivalent to showing a spectral gap/Poincare inequality.</li>
<li>Show that the conditions of the theorem are satisfied: mixing on component chains, and mixing on a certain projected chain. This shows that the simulated tempering chain mixes, if we move the <span class="math inline">\(\beta_i\)</span>’s “inside” the mixture of gaussians. This makes the stationary distribution <span class="math inline">\(\wt p_i\)</span> at each temperature a mixture of gaussians, so is easier to analyze.</li>
<li>Show that <span class="math inline">\(\wt p_i\)</span> are close to the acutal distributions <span class="math inline">\(p_i\)</span>, so that we also have rapid mixing for the original chain.</li>
<li>Some technical details remain that we won’t cover: bounding the error from discretizing the chain, and estimating the partition functions to within a constant factor.</li>
</ol>
<h3 id="markov-chain-decomposition-theorem">Markov chain decomposition theorem</h3>
<h4 id="previous-decomposition-theorems">Previous decomposition theorems</h4>
<p>Madras and Randall’s theorem says that if a Markov chain M mixes rapidly when restricted to each set of the partition, and the “projected” Markov chain mixes rapidly, then M mixes rapidly. The formal statement is the following.</p>
<blockquote>
<p><strong>Theorem (Madras, Randall 02):</strong> For a (discrete-time) Markov chain <span class="math inline">\(M\)</span> with stationary distribution <span class="math inline">\(p\)</span> and a partition <span class="math inline">\(\Om = \bigsqcup_{j=1}^m A_j\)</span> of its state space, <span class="math display">\[\text{Gap}(M) \ge \rc 2 \text{Gap}(\ol M) \min_{1\le j\le m} (\text{Gap}(M|_{A_j})).\]</span></p>
</blockquote>
<p>The projected chain is defined on <span class="math inline">\(\{1,\ldots, m\}\)</span>, and transition probabilities are given by average probability flows between the corresponding sets. More precisely, the probability of transitioning from <span class="math inline">\(j\)</span> to <span class="math inline">\(k\)</span> is as follows: pick a random point in <span class="math inline">\(A_j\)</span>, run the Markov chain for one step, and see what’s the probability of landing in <span class="math inline">\(A_k\)</span>.</p>
<p>This gives a potential plan for the proof. We’re given a mixture of <span class="math inline">\(m\)</span> gaussians. Suppose we can partition <span class="math inline">\(\mathbb R^d\)</span> into <span class="math inline">\(m\)</span> parts - maybe one centered around each gaussian - such that Langevin mixes well inside each set. Choose the highest temperature so that Langvein mixes well on the entire space <span class="math inline">\(\R^d\)</span> there.</p>
<center>
<!--img src="pics/sigma_0.5.png"-->
<img src="pics/partition.jpeg" width="50%" height="50%">
</center>
<p>Then if we also have mixing for the projected chain, this will prove the main theorem. Intuitively, the projected chain would mix rapidly because the highest temperature acts like a bridge. There is a reasonable path from any component to any other component passing through the highest temperature.</p>
<p>There are a lot of issues with this approach. The primary problem is defining the partition. Our first proof followed this plan; later we found a simpler proof with better bounds, which I’ll now describe.</p>
<h4 id="decomposition-theorem-with-sets">Decomposition theorem with sets</h4>
<p>The insight is to work with distributions rather than sets.</p>
<p>There’s an idea in math that a theorem is true for sets, then it’s a special case of a theorem for functions - because sets just correspond to indicator functions.</p>
<p>For simulated tempering Langevin on a mixture of Gaussians, we don’t naturally have a decomposition of the state space, we do have a natural decomposition of the stationary distribution - namely the components of the mixture! Think of this as a “soft partition”.</p>
<p>So instead of partitioning <span class="math inline">\(\Omega\)</span>, we decompose the Markov chain and stationary distribution. We prove a new Markov chain decomposition theorem that allows us to do this.</p>
<blockquote>
<p><strong>Theorem:</strong> Let <span class="math inline">\(M_{\text{st}}\)</span> be a simulated tempering Markov chain (with stationary distribution <span class="math inline">\(p\)</span>) made up of Markov chains <span class="math inline">\(M_i,i\in [L]\)</span>. Suppose there is a decomposition <span class="math display">\[M_i(x,y)=\sum_{j=1}^mw_{ij}M_{ij}(x,y)\]</span> where <span class="math inline">\(M_{ij}\)</span> has stationary distribution <span class="math inline">\(p_{ij}\)</span>. If each <span class="math inline">\(M_{ij}\)</span> mixes in time <span class="math inline">\(C\)</span> and the projected chain mixes in time <span class="math inline">\(\ol C\)</span>, then the simulated tempering chain mixes in time <span class="math inline">\(C\ol C\)</span>.</p>
The projected chain is defined by
<span class="math display">\[\begin{align} L((i,j),(i,j')) &amp;=
\begin{cases}
\fc{w_{i,j'}}{\chi^2_{\text{sym}}(p_{i,j}||p_{i,j'})},&amp;i=i'\\
\fc{1}{\chi^2_{\text{sym}}(p_{i,j}||p_{i',j'}))}
,&amp;i'=i\pm 1\\
0,&amp;\text{else.}
\end{cases}
\end{align}\]</span>
<p>where <span class="math inline">\(\chi^2_{\text{sym}}(p||q)=\max\{\chi^2(p||q),\chi^2(q||p)\}\)</span> is the “symmetrized” <span class="math inline">\(\chi^2\)</span> divergence.</p>
</blockquote>
<p>This theorem is where most of the magic lies, but it is also somewhat technical; see the paper supplement for details. <!--so you can skip it on a first read.--></p>
<h4 id="applying-the-decomposition-theorem">Applying the decomposition theorem</h4>
<p>We consider simulated tempering Langevin diffusion for <span class="math display">\[
\wt p_i \propto \sumo jm w_j \ub{\exp\pa{-\fc{\be_i \ve{x-\mu_j}^2}2}}{\wt p_{ij}}.
\]</span></p>
<p>The Langevin chain decomposes into Langevin on the mixture components. By the decomposition theorem, if the Markov chain with respect to these components mixes well, and the Markov chain on the “projected” chain mixes well, then the simulated tempering chain mixes well.</p>
<ol type="1">
<li>Langevin mixes rapidly for each <span class="math inline">\(\wt p_{ij}\)</span>, in time <span class="math inline">\(O(D^2)\)</span>, by Bakry-Emery.</li>
<li>The projected chain mixes rapidly, in time <span class="math inline">\(O(L^2)\)</span>. To see this, note that by choosing the temperatures close enough, the <span class="math inline">\(\chi^2\)</span> distance between the gaussians in adjacent temperatures is at most a constant, and by choosing the highest temperature high enough, all the gaussians there are also close. Thus, the projected chain looks like <span class="math inline">\(L\)</span> stacks of <span class="math inline">\(m\)</span> nodes, where the nodes in the same stack at adjacent temperatures have probability flow <span class="math inline">\(\Omega(1)\)</span> between them, and the subgraph consisting of nodes at the highest temperature mixes almost immediately.</li>
</ol>
<center>
<img src="pics/proj_chain.png" width="50%" height="50%">
</center>
<p>Thus the simulated tempering chain mixes in time <span class="math inline">\(O(L^2D^2)\)</span>.</p>
<h4 id="simulated-tempering-mixes-for-p">Simulated tempering mixes for <span class="math inline">\(p\)</span></h4>
<p>But we need mixing for simulated tempering where the temperature is outside the sum, <span class="math display">\[
p_i \propto \sumo jm w_j \exp\pa{-\fc{\be_i \ve{x-\mu_j}^2}2}.
\]</span> This follows from mixing for <span class="math inline">\(\wt p_i\)</span>, plus the fact that the ratio $ p_i/p_i$ is bounded: <span class="math inline">\(\fc{p_i}{\wt p_i}\in [w_{\min}, \rc{w_{\min}}]\)</span>. We lose a factor of <span class="math inline">\(\rc{w_{\min}^2}\)</span>.</p>
<h2 id="takeaways">Takeaways</h2>
<ul>
<li>“Beyond log-concavity” for sampling is the analogue of “beyond convexity” for optimization</li>
<li>There is a spectral decomposition lemma for Markov chains based on decomposing the <em>Markov chain</em> rather than just the <em>state space</em>, and that helps prove mixing for simulated tempering.</li>
<li>Provable sampling holds for a prototypical multimodal distribution: mixture of Gaussians.</li>
</ul>
<h2 id="further-directions">Further directions</h2>
<p>Here are further directions and open questions we would like to explore. Feel free to get in touch if you have ideas!</p>
<ol type="1">
<li>How do we deal with gaussians with different variance?
<ul>
<li>You might have wondered why we needed the gaussians to have the same covariance, and how robust the results are to different covariances. We can allow the variances to be at most a factor of <span class="math inline">\(1+\fc Cd\)</span> apart in each direction. In general different variances have the problem that they change the mixture coefficients at the different levels - for a skinny gaussian, it could be exponentially small at the highest temperature, and large at the lowest temperature. Thus it’s hard to even get into the “attractor region” for that gaussian at the highest temperature - like finding a needle in a haystack. One assumption we can use to get around this is to assume we’re given points near each of the modes. Then we can hope to have an unbiased sample by combining the samples starting from each of those modes, with the right coefficients.</li>
</ul></li>
<li>Find practical algorithms for testing whether a Markov chain has mixed.</li>
<li>Carry out average-case analysis for distributions of interest.
<ul>
<li><p>In real-life, the distributions we want to sample from are not as simple as a polynomial mixture of gaussians. For example, consider clustering. Suppose a simple model, that there are m clusters, each has some mean <span class="math inline">\(\mu_j\)</span>, and each point is equally likely to be drawn from each cluster. Then the posterior distribution looks like a product of sums <span class="math inline">\(\prod_{n=1}^N \pa{\sumo jm \rc m \exp\pa{-\fc{\ve{x_n-\mu_j}^2}2}}\)</span>, which when expanded out, has exponentially many terms, so our results don’t immediately apply.</p>
<p>Also, in many distributions of interest, we don’t have a mixture of the probability distribution but rather, <span class="math inline">\(f\)</span> is a combination of simpler functions. In other words, <span class="math inline">\(p\propto e^{-\sum_j w_jf_j}\)</span> rather than <span class="math inline">\(p\propto \sum_j w_j e^{-f_j}\)</span>. When this combination happens in the exponent, the decomposition approach doesn’t work so well.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
<p>Can we come up with provable results for Ising models, stochastic/censored block models, or RBM’s?</p>
It would be great to find other uses for our simulated tempering decomposition theorem - in principle the theorem could even apply when there are exponentially many modes, as long as we create a refining partition such that there is no “bottleneck” at any point.<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></li>
</ul></li>
<li>What are the guarantees for other temperature heuristics used in practice, such as annealed importance sampling or parallel tempering?</li>
</ol>
<!--
### Interlude: discrete vs. continuous time Markov chains

### Proof of decomposition theorem

(follow ppt)

# FAQ's

talk about different decomposition theorems - one-step vs. zero-step.

# Captain's log

In this section I detail the journey towards the result following the philosophy [here](Proofs and stories as obstacle avoidance).
-->
<!--
# Introduction

Summary:

* I compare sampling to *optimization*. "Beyond log-concavity" is the analogue of "beyond convexity" in the Bayesian world. Moreover, there are close connections between optimization and sampling, so there's reason to study sampling even if you only care about optimization.
* Sampling is a fundamental task in Bayesian statistics.
* To help with sampling, temperature-based methods are widely used, but lack theoretical analysis.

## Optimization vs. sampling

The goal in optimization is to find the minimum of a function $f$. 

When $f$ is convex, this is well-understood and can be solved using local search algorithms such as gradient descent.

When $f$ is non-convex, the problem is NP-hard in the worst-case, but algorithms often work well in practice.

Here is a comparison of convex and non-convex optimization, the "great divide" of optimization.

| Convex optimization | Non-convex optimization |
| --- | --- |
| Local minimum = global minima | Possibly bad local minima |
| Gradient descent finds global minimum | Gradient descent can be bad |
| Provable algorithms with beautiful mathematics | NP-hard in the worst-case (messy), but often works in practice |
| | Modern optimization problems (e.g. machine learning) are often non-convex.|



# FAQ

Q: Why not simulated annealing?

Q: What about gaussians of unequal variance?

Q: If the sample at time $t$ isn't from the $L$th level, can't you just take the first sample after that that is in the $L$th level?
-->
<p>Thoughts, questions, typos? Leave a comment below.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>For example, consider when <span class="math inline">\(p(x)\)</span> has peaks around the points of the boolean cube that satisfy a SAT formula; this is #P-hard to sample from.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>The difference between their work and our work is that we care about about actual mixing time, rather than just hitting time for certain sets. By itself Langevin diffusion does not work well with deep, separated local minima.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>The reason for the square-root scaling is that noise from Brownian motion scales as the square root of the time elapsed (the standard deviation of a sum of <span class="math inline">\(n\)</span> iid random variables scales as <span class="math inline">\(\sqrt{n}\)</span>).<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Changing the temperature is just changing the scaling of the gradient step with respect to the noise.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>This definition is stated for continuous Markov chains. By rate <span class="math inline">\(\lambda\)</span> I mean that the time between swaps is an exponential distribution with decay <span class="math inline">\(\lambda\)</span> (in other words, the times of the swaps forms a Poisson process). A version for discrete Markov chains is to swap with probability <span class="math inline">\(\lambda\)</span> and to follow the current chain with probability <span class="math inline">\(1-\lambda\)</span>. Note that simulated tempering is traditionally defined for discrete Markov chains, but we will need the continuous version for our proof.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>They proceed by first bounding the spectral gap for parallel tempering, and then showing the gap for simulated tempering is lower-bounded in terms of that. However, in our experience, bounding the spectral gap for simulated tempering directly is easier!<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Think of the downstairs combination as an OR combination, the upstairs one as a AND.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>We stated it in the case where we had the same partition at every level. The more general form of the theorem works even if the partitions on different. The bound could be polynomial even if there are exponentially many components.<a href="#fnref8">↩</a></p></li>
</ol>
</section>

  </div>
  
    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
  
</div>
]]></summary>
</entry>
<entry>
    <title>General advice</title>
    <link href="http://holdenlee.github.io/General%20advice.html" />
    <id>http://holdenlee.github.io/General%20advice.html</id>
    <published>2017-11-18T00:00:00Z</published>
    <updated>2017-11-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">

  <div id="content">
    <div class="page header">
      <h1> General advice </h1>
    </div>
    
    
    <div class="info">
      
       
        <p>Posted: 2017-11-18 
          , Modified: 2017-11-18 
	</p>
      
       <p>Tags: <a href="/tags/advice.html">advice</a>, <a href="/tags/life.html">life</a></p> 
       <p>Parent: <a href="/Views.html">Views</a></p> 
	   <p>Children: </p> 
    </div>
    
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#links">Links</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>Read. You can’t count on others to tell you what to read. There are many books I’ve read that changed my views that I wished I’d read earlier. Reading for pleasure is good, but also read strategically. Go out of your way to figure out a list of books that are important and for what reasons, and read some of them. Sometimes adults will just tell you to read, but not try and pick the best books for you to read. In particular, adults have a tendency to just push story-books they feel are age-appropriate. Read nonfiction, or fiction with Views. Don’t believe what you read. Read things you disagree with. Read Ayn Rand and Karl Marx, and then form your own opinion. Especially read about big ideas. Read life advice by successful people. Your brain will feel exploded afterwards, and you’ll feel paralyzed for a while afterwards (if you’re anything like me), so maybe don’t do this too often, but you want to know all your options and possible strategies early. Find things to follow, like blogs with ideas, debates. You don’t have to follow them consistently - I regularly go for extended periods where I consume little media, because that makes it easier to focus - but know they’re there.</p>
<p>Strategize your distractions. It’s hard to be productive every minute - and distractions smoothen life out. The key is to have high-quality distractions. Ex. reddit front page rarely has anything meaningful, you could instead look at subreddits that pertain to your interest. Find the distractions that are meaningful to you, like webcomics and blogs. These are high-quality distractions. Low-quality distractions are things like checking your email every few minutes.</p>
<p>Your job isn’t to know what you want to do: it’s to get yourself exposed to interesting things, to things that are beautiful and to things that give you power (ex. knowledge).</p>
<p>Develop taste. Don’t just do things. Don’t just play computer games. If you like computer games, play good computer games. Find the games that have really creative storytelling, or really good mechanics, or are revolutionary in some way.</p>
<p>Do projects. Have experience in coming up with an idea or initiative you want to pursue, and then pursuing it - rather than just doing something someone told you to do.</p>
<p>Develop a love for learning. A love for learning means you’ll learn, even when no one recognizes you for it - when you don’t win competitions, when you don’t get certificates or badges. Some people were born with this love; some had it instilled in them from their family or community. But even if you haven’t, you can still develop it. It’s not easy. Pride is dangerous: beware of taking too much pleasure in doing something well. A litmus test is would you still do it if you didn’t get the recognition? Many people hit a wall in college: they didn’t realize all the hidden motivations that compelled them to learn (ex. being better than other people), and these motivations dry up (ex. they are suddenly not better than everyone else around them). The solution is to have motivations to learn that won’t dry up. Find them. It’s fine to be motivated by pride and competition - but make sure you have something more substantial to lean on. Get off your crutches early. Know that love for learning often doesn’t come automatically, but it is a very rewarding thing to develop.</p>
<p>Learn different things. You don’t have to cover everything - you can’t cover everything. But learn different things. The first step in learning something, unless you have a good sense of it already, is not to pick a random textbook and start reading. People are passionate about subjects for a reason - figure out what it is that makes them tick. Figure out what is “good work” in the subject. Figure out what are the books, classes, exercises, and projects that will help you learn the subject, based on your experience. This used to be much harder, but now there’s the Internet. There are many recommendations online, many online courses and course materials to pursue. Sometimes the official sources - ex. textbooks - are hard to penetrate. Find other sources - blog posts, videos, whatever. There are many roads. Don’t dismiss entire subjects as “not interesting.” You can dismiss them as “not my focus right now.” Think of every subject and contemplate on it a little. What are the “classics”? Why do people study them? Ask these questions. Figure out why these subjects are interesting, why they are worth learning, and then you can make your decisions on what to focus on learning. It’s much, much easier to explore things earlier than later. When your interests change, don’t force them to stay on the same track. Keep your life plans flexible. When you have doubts about whether you want to do X or Y, remember that doubts grow when suppressed. Doubts want to either annihilate the object of doubt, or be annihilated. So try out that other thing, and you’ll know which is the outcome. Either is better than suppressed doubt.</p>
<p>Write everything down. Figure out (after some experimentation) a consistent way to take notes so that you can search up anything important you’ve ever learned. (I recommend <a href="https://workflowy.com/invite/fdc650b.lnx">workflowy</a> or <a href="https://dynalist.io/invite/6Chr2g">dynalist</a>, but there are many options: OneNote, EverNote, etc.) You can learn things halfway and then pick up where you left off. “Disorganization” is not a unchangeable trait. Fix it. People underutilize the organizational and remembering power of computers, or even paper and pencil. Carry a notebook, and write down things to remember. Don’t just absorb and copy. Write things in your own words. Write down your questions. Questions are the knives that cut through the curtain of life. Find opportunities to ask the questions that you write down. Write down the answers when you find them.</p>
<h2 id="links">Links</h2>
<ul>
<li><a href="http://www.paulgraham.com/hs.html">What you’ll wish you’d known, Paul Graham</a> (see also <a href="https://www.quora.com/How-can-one-be-academically-successful-in-high-school-What-might-one-regret-not-doing-while-in-high-school-What-are-some-general-tips-you-would-give-to-somebody-to-have-the-best-academic-experience-possible/answer/Qiaochu-Yuan-1">Qiaochu’s answer</a>)</li>
<li><a href="https://putanumonit.com/2017/10/11/winning-is-for-losers/">Winning is for losers, Jacob Falkovich</a></li>
<li><a href="http://theamericanscholar.org/the-disadvantages-of-an-elite-education/">Disadvantages of an elite education</a></li>
</ul>

  </div>
  
    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
  
</div>
]]></summary>
</entry>
<entry>
    <title>Surrounded by music</title>
    <link href="http://holdenlee.github.io/Surrounded%20by%20music.html" />
    <id>http://holdenlee.github.io/Surrounded%20by%20music.html</id>
    <published>2017-08-18T00:00:00Z</published>
    <updated>2017-08-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">

  <div id="content">
    <div class="page header">
      <h1> Surrounded by music </h1>
    </div>
    
    
    <div class="info">
      
       
        <p>Posted: 2017-08-18 
          , Modified: 2017-08-18 
	</p>
      
       <p>Tags: <a href="/tags/music.html">music</a>, <a href="/tags/art.html">art</a>, <a href="/tags/teach_kid.html">teach_kid</a>, <a href="/tags/teaching.html">teaching</a></p> 
       <p>Parent: <a href="/Music.html">Music</a>, <a href="/Views.html">Views</a></p> 
	   <p>Children: </p> 
    </div>
    
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>A conversation between friends.</p>
<blockquote>
<p>J: I want my kids to be surrounded by music.</p>
<p>M: That’s easy - just give them iPods!</p>
<p>J: No, I don’t mean that… I want them to be banging on pots and pans.</p>
</blockquote>

  </div>
  
    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
  
</div>
]]></summary>
</entry>
<entry>
    <title>Forget your index cards</title>
    <link href="http://holdenlee.github.io/Forget%20your%20index%20cards.html" />
    <id>http://holdenlee.github.io/Forget%20your%20index%20cards.html</id>
    <published>2017-08-18T00:00:00Z</published>
    <updated>2017-08-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">

  <div id="content">
    <div class="page header">
      <h1> Forget your index cards </h1>
    </div>
    
    
    <div class="info">
      
       
        <p>Posted: 2017-08-18 
          , Modified: 2017-08-18 
	</p>
      
       <p>Tags: <a href="/tags/index%20cards.html">index cards</a></p> 
       <p>Parent: <a href="/Views.html">Views</a></p> 
	   <p>Children: </p> 
    </div>
    
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>Make lots of <a href="index%20cards.html">index cards</a>, and then forget them.</p>
<p>Index cards are pensieves. They will remember for you, even when you forget.</p>
<p>If you keep them in mind at all times, you’re holding many little stones, and don’t have the space to come up with new things.</p>
<p>A musician learns music theory in order to compose and play well, but doesn’t think about it consciously in the actual act of playing.</p>

  </div>
  
    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
  
</div>
]]></summary>
</entry>
<entry>
    <title>Bite-sized writing for powerful thinking</title>
    <link href="http://holdenlee.github.io/Bite-sized%20writing%20for%20powerful%20thinking.html" />
    <id>http://holdenlee.github.io/Bite-sized%20writing%20for%20powerful%20thinking.html</id>
    <published>2017-08-18T00:00:00Z</published>
    <updated>2017-08-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">

  <div id="content">
    <div class="page header">
      <h1> Bite-sized writing for powerful thinking </h1>
    </div>
    
    
    <div class="info">
      
       
        <p>Posted: 2017-08-18 
          , Modified: 2017-08-18 
	</p>
      
       <p>Tags: <a href="/tags/index%20cards.html">index cards</a></p> 
       <p>Parent: <a href="/Views.html">Views</a></p> 
	   <p>Children: </p> 
    </div>
    
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#warm-up">Warm-up</a></li>
 <li><a href="#models-of-writing">Models of writing</a><ul>
 <li><a href="#model-1">Model 1</a></li>
 <li><a href="#model-2">Model 2</a></li>
 <li><a href="#comparison">Comparison</a></li>
 <li><a href="#aside-english-class">Aside: English class</a></li>
 </ul></li>
 <li><a href="#how-to-have-ideas">How to have ideas</a><ul>
 <li><a href="#but-i-dont-have-anything-worth-writing-down">But I don’t have anything worth writing down!</a></li>
 <li><a href="#index-cards-as-pensieves">Index cards as pensieves</a></li>
 <li><a href="#system">System</a></li>
 <li><a href="#exercise">Exercise</a></li>
 </ul></li>
 <li><a href="#how-to-write-well">How to write well</a><ul>
 <li><a href="#the-inversion-heuristic">The inversion heuristic</a></li>
 <li><a href="#exercise-1">Exercise</a></li>
 </ul></li>
 <li><a href="#conclusion">Conclusion</a><ul>
 <li><a href="#moonwalking-with-einstein">Moonwalking with Einstein</a></li>
 <li><a href="#writing-for-all-aspects-of-life">Writing for all aspects of life</a></li>
 </ul></li>
 <li><a href="#other-references-and-links">Other references and links</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>Note: This is a loose transcript of a course for <a href="https://espr-camp.org/">ESPR 2017</a>, hence the colloquial/oral style.</p>
<h2 id="warm-up">Warm-up</h2>
<ol type="1">
<li>Look at several pieces of writing from this <a href="http://tiny.cc/espric">list</a>.</li>
<li>Answer these questions:
<ol type="1">
<li>What are features of “this kind of writing”?</li>
<li>How would you go about writing “this kind of writing”?</li>
</ol></li>
</ol>
<h2 id="models-of-writing">Models of writing</h2>
<h3 id="model-1">Model 1</h3>
<p>You might have a model of writing that looks something like this. You get an assignment from language class: write an essay about a certain topic. Then you sit down,</p>
<ol type="1">
<li>think very hard to come up with some thoughts, and</li>
<li>work really hard to write it all down, and</li>
<li>it doesn’t look so good, so you dress it and make the sentences more eloquent.</li>
</ol>
<p>Finally you finish and turn it in and don’t think about it until you get back your paper.</p>
<p>PICTURE</p>
<p>In summary, the model is</p>
<ol type="1">
<li>You have an idea or purpose in your head.</li>
<li>You write down the idea and dress it up.</li>
</ol>
<p>This isn’t how most writing works (in the real world)!</p>
<!--You might think that writing is a long difficult thing, and you wouldn't want to do it outside of English class.-->
<h3 id="model-2">Model 2</h3>
<p>Here’s an alternate model of writing.</p>
<ul>
<li>You have a bit of an idea in your head.</li>
<li>You write it down - it’s a small idea, so it’s just a sentence or two.</li>
<li>Later, you have another idea.</li>
<li>You write the idea down.</li>
<li>After a while, you look at your writing, and because paper has more memory than your head, you see connections between ideas and they “glom” together into a larger idea. You see that some ideas are wrong, and replace them with correct ones. You have improved ideas in your head.</li>
<li>You go back and forth between more accurate or beautiful thoughts, and clearer and more compelling writing.</li>
<li>At the end, you have these clusters of ideas, and you want to tell other people about them. You arrange these ideas, adds some section headers and some connecting bits, and you’ve finished an essay, or maybe a book.</li>
</ul>
<p>PICTURE</p>
<h3 id="comparison">Comparison</h3>
<p>Let’s compare the two models.</p>
<ul>
<li>In the previous model, you get an idea (no matter whether it’s good or bad), write it all out, and <em>then</em> try to make the writing good. Here, the process of building ideas and writing are tightly linked.</li>
<li>In either model, writing takes work. But instead of being this big difficult thing, you can view writing as an incremental thing where work feels more spread out, where every step feels more natural and yummy.</li>
</ul>
<h3 id="aside-english-class">Aside: English class</h3>
<p>I want to put this in the perspective of English (or language arts) class. English class made me confused about writing. See <a href="The%20beauty%20of%20ideas%20vs%20the%20beauty%20of%20writing.html">The beauty of ideas vs the beauty of writing</a>.</p>
<p>Writing isn’t just for academics. You can write the ideas that come to you in daily life.</p>
<h2 id="how-to-have-ideas">How to have ideas</h2>
<h3 id="but-i-dont-have-anything-worth-writing-down">But I don’t have anything worth writing down!</h3>
<p>Who writes posts on facebook? Or any words on social media?</p>
<p>You are writers (maybe not good, or long-form writers, but writers nonetheless). You have things that you want to tell your friends, stories or activities you want to share - you just don’t associate your thoughts with things that are written down, or the things that are written down with “writing” which may seem reserved for something serious and academic. And if you don’t think of your thoughts as worth recording, they can slip by and you can forget them.</p>
<p>I’ve had people tell me they’re not good at writing, but when I talk to them, I have a fascinating conversation about something they’re interested in - and if I just transcribed the interview, it might need some editing, but it would be a good piece of writing.</p>
<p>People often ask writers where they get their ideas from…</p>
<p><a href="http://www.neilgaiman.com/Cool_Stuff/Essays/Essays_By_Neil/Where_do_you_get_your_ideas%3F">Neil Gaiman said</a></p>
<blockquote>
<p>You get ideas from daydreaming. You get ideas from being bored. You get ideas all the time. The only difference between writers and other people is we notice when we’re doing it.</p>
<p>You get ideas when you ask yourself simple questions. The most important of the questions is just, What if…? …If only…</p>
</blockquote>
<h3 id="index-cards-as-pensieves">Index cards as pensieves</h3>
<p>In the Harry Potter world, “pensieves” are these basins you can put your memories into, so that you can review them anytime later.</p>
<p>I think this is awesome - when there’s something that you keep thinking about, or want to reference later, wouldn’t it be great if you could just capture it and put it somewhere?</p>
<p>We don’t have pensieves, but we do have writing. When you write a thought down, you can rethink it anytime without fear of forgetting it, and build on it.</p>
<p>PICTURE</p>
<p>I like to think of index cards as pensieves. They don’t have to be <em>literally</em> index cards.</p>
<p>An index card is a natural size for writing. Imagine something you would write on an index card - like Trefethen’s index cards. An index card has the feature of not being too large - there’s not much space - and the feature of being a coherent idea (or cluster of ideas).</p>
<p>Some of the examples are from Lloyd Trefethen, who wrote a lot of his thoughts on 4x6 index cards and then published around 200 into a book.</p>
<p>When you have an idea “index-carded”, you can then hold a concept clearly in your mind and easily transmit it to others with good fidelity (and they can transmit it to yet more people). Something with the size and coherence of an index card is <em>mimetic</em>.</p>
<p>Here’s an <a href="index%20cards.html">index card on index cards</a>.</p>
<h3 id="system">System</h3>
<p>In order for this model of writing to work, you need a notetaking system. I don’t mean a notetaking system in the restricted sense of taking down an hour-long lecture; I mean a system where you can easily write down your thoughts at any time.</p>
<p>The two criteria for such a system are:</p>
<ol type="1">
<li>It has low activation energy.</li>
<li>It is easily searchable.</li>
</ol>
<p>You can use any notetaking framework. I recommend using <a href="https://workflowy.com/invite/fdc650b.lnx">workflowy</a> or <a href="https://dynalist.io/invite/6Chr2g">dynalist</a>. You can use a wiki, blog, or journal for writing up longer posts. When you’re out and around and you have a good idea, you can write them down on your phone or pocket notebook.</p>
<h3 id="exercise">Exercise</h3>
<p>Come up with a list of things that you want to write about. Nothing is too small. Good search terms:</p>
<ol type="1">
<li>Hobby, interest, topic, or activity you like, especially something that is less common.</li>
<li>Things that you keep coming back to - things you want to pensieve.</li>
<li>Personal philosophy - what’s a way you look at the world that’s unique to you?</li>
<li>Thing that happened to you, that tickled you in some way.</li>
<li>What do you want to communicate to people? If you could give everyone in the world (or your community) an index card, what would be on it?</li>
<li>A book/movie/etc. you like. A person you admire. What are the key ideas or qualities?</li>
<li>Things you like to tell other people in conversation</li>
</ol>
<p>Note that Trefethen’s index cards are often about a thing that happens in daily life, plus a reflection on it. Also note how he can use an experience to define a whole category of experiences.</p>
<p>Now that we have ideas, how do we write them well?</p>
<h2 id="how-to-write-well">How to write well</h2>
<h3 id="the-inversion-heuristic">The inversion heuristic</h3>
<p>There’s a lot of specific advice out there (see for example <a href="What%20I%20learned%20from%20Patrick%20Winston.html">What I learned from Patrick Winston</a>); I’ll just give one general principle, the <strong>inversion heuristic</strong>.</p>
<p>The inversion heuristic is: Put yourself in the reader’s shoes. What do they want? How can you make the writing compelling and useful to them?</p>
<p>Taking a coarse view, there are two things (nonfiction) writing needs to do.</p>
<ol type="1">
<li>Say why the topic is interesting.</li>
<li>Deliver the information so that the structure in your head becomes the structure in the reader’s head. For example, if you’re teaching someone an activity, give the the steps clearly. (Try to communicate the structure - if it’s a list, give a list. If it’s a dialogue in your head, give it as a dialogue - you aren’t constrained to a certain format, like you learn in English class. If a picture helps, draw it in.)<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></li>
</ol>
<p>This is very similar to teaching: imagine you were learning the material for the first time - what would you want?</p>
<ol type="1">
<li>You want to know why you’d even care about the topic - why is it interesting?</li>
<li>You want clear instructions on how to do the thing.</li>
</ol>
<p>Note that many of the things that work to get better for writing or more generally communication for other people, also help even if you’re only making notes to yourself. For example, in order for your notes to help you remember your thoughts, you must write clearly; on the other hand, being concise means writing and reading doesn’t take up a lot of your time, or fill your head with irrelevant details.</p>
<p>One thing that you <em>do</em> have to do more of when writing to other people is to make a bridge - for example make them interested if they’re not already as interested as you are, and give them background they need to understand. <!--However, this can often clarify your own thinking, as often you don't truly understand something until you can explain it from scratch. --></p>
<h3 id="exercise-1">Exercise</h3>
<ol type="1">
<li>Choose one thing from your list, that you wanted to write about.</li>
<li>Pair up.</li>
<li>Interview your neighbor about their topic. Try to ask the questions so that YOU can write about it. Then write an outline. Don’t stop your line of questioning until you feel you see why their thing is interesting, and break it down into its parts.</li>
</ol>
<p>The point of the exercise is: When you’re writing by yourself, you will be your own critic, imagining yourself as a reader who needs to be convinced and taught. That’s a skill to be developed, so here, you have someone else to be a critic.</p>
<p>You want your writing to be compelling, and the arguments to follow naturally. Writing your own ideas, you may miss something that you think is “obvious”, or assume the reader already thinks the material is interesting or conceptualizes it in a similar way as you. Or you may have cached an argument that you’ve heard and are just repeating it without thinking it through. Eventually, you want to be your own critic in terms of exposing these gaps. Finding these gaps is useful not just for communicating to others, it can help you realize there were gaps in your knowledge and improve your conception of the idea!</p>
<h2 id="conclusion">Conclusion</h2>
<h3 id="moonwalking-with-einstein">Moonwalking with Einstein</h3>
<p>In <a href="https://www.goodreads.com/book/show/6346975-moonwalking-with-einstein?ac=1&amp;from_search=true">Moonwalking with Einstein</a>, the author talks about his journey of training for the International Memory Olympiad, and on the way, gives the history of writing and the history of memorization.</p>
<p>Before the printing press, having copies of manuscripts was costly. Learned people memorized entire books in their heads, so they could conjure up the knowledge they needed anytime.</p>
<p>In the modern age, memorization can seem obsolete, because the Internet gives instant information at our fingertips. Some people worry that this has dumbed us down.</p>
<p>Joshua Foer presents the following dilemma: In this age, we read a lot of books and articles - but how much of it do we actually remember? If we didn’t remember it, what was the point of reading it?</p>
<p>One answer to this dilemma is as follows. We don’t need to memorize everything, because we have information at our fingertips - but neither are we intelligent by having Internet access alone. We are overwhelmed by that raw information. Instead, we maintain a kind of superstructure of “notes” between us and all the information out there.</p>
<p>I want to end with my conception of what being “well-read” is. It’s not sufficient to just read a bunch of books if you forget what you read. Read widely, and reflect, record, and summarize things that you read.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> Remember that they can be bite-sized. Index into books and articles.</p>
<h3 id="writing-for-all-aspects-of-life">Writing for all aspects of life</h3>
<p>Writing notes down, organizing, and later reflecting or expanding them is a habit that’s useful in many areas of life, and that will have more gains the more you develop it.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<p>Here are some examples:</p>
<ul>
<li>How many of you have gone to a talk, and felt you didn’t get anything out of it? Here’s a suggestion: try to get three things out of a talk. <a href="http://math.stanford.edu/~vakil/threethings.html">If you can get three things out of a talk, it was a successful talk.</a> Note that three things can fit on an index card.</li>
<li>This isn’t just for “rational” stuff. Artists do it too. A painter might have post-it notes all over their easel.</li>
<li>Write down concise articulation of what makes something good. I recommend the following exercise for creative writing: take some books you really like. Think about and write down what makes them <em>interesting</em> and <em>different</em>. (For example, for Lord of the Rings: It’s not a story about an ambitious person setting out to find treasure, but a story about a non-ambitious person (Hobbit) setting out to destroy treasure (the ring).)</li>
<li>Creative writing: go back and forth between exploratory writing (unstructured) and outlining (structured). See <a href="http://www.writingexcuses.com/2017/05/28/12-22-hybrid-outlining-and-discovery-writing/">here</a>. Kazuo Ishiguro talks about “bottling up” in his <a href="https://holdenlee.wordpress.com/2014/02/18/kazuo-ishiguro-on-writing/">interview</a>.</li>
<li>It’s useful to write down summaries/notes of many things, like conversations and people (Farley file).</li>
<li>How do you remember a story for storytelling (or other oral presentation)a Imagine it as a scene (like a visual index card).</li>
</ul>
<p>One thing to consider doing is to start a blog! I’m happy to help you set it up.</p>
<p>Take some index cards! Write things on them. Your mind is a net, capturing ideas as you move through the world…</p>
<p>There’s a table in the googledoc. I encourage you to post your “index cards” there. (You can also take a picture of your index card and upload it.)</p>
<h2 id="other-references-and-links">Other references and links</h2>
<ul>
<li><a href="http://slatestarcodex.com/2016/02/20/writing-advice/">Nonfiction writing advice (Slatestarcodex)</a>: highly recommended</li>
<li><a href="https://usamo.wordpress.com/2015/03/14/writing/">Writing for thinking (Evan Chen)</a>.</li>
<li>My (very abbreviated notes) on a CFAR alumni reunion class, <a href="https://workflowy.com/s/BeBJ.lb28OIC55u">Notetaking 101: Growing an exobrain (Joel Solymosi)</a>.
<ul>
<li><a href="http://www.abc.net.au/radionational/programs/philosopherszone/the-extended-mind/2986780">The extended mind</a>.</li>
</ul></li>
<li><a href="What%20I%20learned%20from%20Patrick%20Winston.html">What I learned from Patrick Winston</a>.</li>
</ul>
<!--
* [Notes on writing about books](https://holdenlee.wordpress.com/2015/03/22/notes-on-writing-about-books/): my suggestions on writing about books
-->
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Minsky does this, e.g. in <a href="https://web.media.mit.edu/~minsky/Introduction.html">The Emotion Machine</a>. Here is one article I wrote as a conversation: <a href="http://holdenlee.github.io/Conversation%20on%20curiosity.html">Conversation on curiosity</a>.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>See my <a href="https://holdenlee.wordpress.com/2015/03/22/notes-on-writing-about-books/">suggestions on writing about books</a>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>One warning: when you’ve written too much, it can be easy to get sucked into reviewing your writing. <a href="Forget%20your%20index%20cards.html">Forget your index cards</a><a href="#fnref3">↩</a></p></li>
</ol>
</section>

  </div>
  
    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
  
</div>
]]></summary>
</entry>
<entry>
    <title>X vs Myopic X</title>
    <link href="http://holdenlee.github.io/X%20vs%20Myopic%20X.html" />
    <id>http://holdenlee.github.io/X%20vs%20Myopic%20X.html</id>
    <published>2017-08-13T00:00:00Z</published>
    <updated>2017-08-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">

  <div id="content">
    <div class="page header">
      <h1> X vs Myopic X </h1>
    </div>
    
    
    <div class="info">
      
       
        <p>Posted: 2017-08-13 
          , Modified: 2017-08-13 
	</p>
      
       <p>Tags: <a href="/tags/Ayn%20Rand.html">Ayn Rand</a>, <a href="/tags/creativity.html">creativity</a>, <a href="/tags/egotism.html">egotism</a>, <a href="/tags/flaws.html">flaws</a>, <a href="/tags/goals.html">goals</a>, <a href="/tags/love.html">love</a>, <a href="/tags/myopia.html">myopia</a>, <a href="/tags/remix.html">remix</a></p> 
       <p>Parent: <a href="/Views.html">Views</a></p> 
	   <p>Children: </p> 
    </div>
    
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>The myopic x problem is the problem where I’m motivated by x, but I <em>cling</em> to x, and won’t do things that help me achieve x if they involve stepping outside of x for a moment. So being myopically x hinders my accomplishing x. I have the myopic egotism problem: when becoming a better person (ultimate goal is egotistic) means forgetting myself and being open and listening to other people (which involves temporarily suspending egotism), I have trouble. The myopic creativity problem is when I put myself in front of an empty screen and try to write, when coming up with something to write involves reading, watching, and studying books/movies/etc., talking to and doing things with people, and learning more about the world. Myopic egotism and myopic creativity together make me think everything I do should come from myself, and prevent me from “standing on the shoulders of giants.”</p>
<p>(On friendship and love I think I have the opposite problem: I’m farsighted, looking in the distance, wanting these connections because of the benefits they will bring, rather than wanting them in themselves. I.e. learning:creating::friendship:(everything friendship leads to), where I’m myopic in the second component, so I overlook the first. As a contrast, <a href="https://www.goodreads.com/book/show/13037.Justine">Justine</a> is about myopic love.</p>
<p>The thing with ulterior motives (do A in order to B) is that although I can’t deny their existence, I have to get myself to <em>not think about</em> B and get myself to <em>truly love</em> A. The only way to truly be knowledgeable is to love learning; the only way to truly enrich myself is to cultivate love and friendship, without thinking of these as for the ulterior purpose of cultivating myself.)</p>
<p>It’s the same with research: I spend too much time trying to get an idea to work, so I can publish it and Have Done Something New! when instead I should ask myself things like, is this likely to work? what’s the best use of time? what things should I understand better before I try to come up with something new? what foundational things should I be learning?</p>
<p><a href="http://lesswrong.com/lw/oh/righting_a_wrong_question/">Why do I think</a> this is circular? Because I think, “once I create something truly new, then I’ll have the confidence that I’m not just a rehash, and then I can go out and learn stuff without worrying whether I can be original.” This means that I shouldn’t change my current course—I should keep spending a lot of my effort on creating, rather than putting the creating aside. The circularity comes from (1) creating requires me to learn/absorb stuff, (2) I don’t want to learn/absorb a lot of stuff until I’ve proved that I can create something.</p>
<p>The myopic creativity that I’m talking about, I think, is a bastardized version of what an artist would call “creativity.” <a href="http://www.brainpickings.org/index.php/2011/08/01/networked-knowledge-combinatorial-creativity/">A lot of creativity is remix</a>. It’s being “my brain is open”: not a flow of information <em>out</em>, but a flow of information <em>in</em>. I try to tell myself that life is remix. But I have a hard time having faith in it.</p>
<p>The catch-22 is illusory though. (1) is true regardless of whether I want to believe it or not. (2) is in my head: it’s a “want” not a “need.” (Like men saying they have to “satisfy their needs,” ugh.)</p>
<p>How is this related to Ayn Rand style egoism? I like her teachings. But I think one has to be very careful because the idea of egoism is easy to misinterpret. It’s easy to <a href="http://english.stackexchange.com/questions/7482/whats-the-difference-between-egotism-and-egoism">confuse egoism and egotism</a>; I use “egotism” to refer to “myopic egoism.” Egoism, done right, includes a (sometimes difficult) realization that even when the end goal is benefiting yourself, you’ll have to step outside yourself to accomplish it—you’ll need your friends’ help, you’ll need to be humble and learn from the masters. Egotism is refusing to step outside yourself for even a moment, and it remains egotism even if you try to label it “egoism.”</p>
<p>The essay <a href="http://lesswrong.com/lw/os/joy_in_discovery/">Joy in Discovery</a>: that’s exactly the attitude I need to have. This reminds me of another Ayn Rand bit: she always says that when you enjoy something, that pleasure is <em>yours</em>. She affirms that [the way you relate to something making you happy] cannot be taken away from you. So even if you’re not a good painter at all, and you don’t own any works of art, you can walk in the museum and get a <em>uniquely personal experience</em>.</p>

  </div>
  
    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
  
</div>
]]></summary>
</entry>
<entry>
    <title>What writers want</title>
    <link href="http://holdenlee.github.io/What%20writers%20want.html" />
    <id>http://holdenlee.github.io/What%20writers%20want.html</id>
    <published>2017-08-13T00:00:00Z</published>
    <updated>2017-08-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">

  <div id="content">
    <div class="page header">
      <h1> What writers want </h1>
    </div>
    
    
    <div class="info">
      
       
        <p>Posted: 2017-08-13 
          
	</p>
      
       <p>Tags: <a href="/tags/writing.html">writing</a>, <a href="/tags/desire.html">desire</a>, <a href="/tags/quote.html">quote</a></p> 
       <p>Parent: <a href="/Writing.html">Writing</a></p> 
	   <p>Children: </p> 
    </div>
    
    
  </div>
  <!--/div-->

  

  <div class="blog-main">
    <blockquote>
<p>“An artist does not live a personal life as we do, he hides it, forcing us to go to his books if we wish to touch the true source of his feelings… Underneath all his preoccupations with sex, society, religion, etc. there is, quite simple, a man tortured beyond endurance by the lack of tenderness in the world.” –Justine, Lawrence Durrell</p>
</blockquote>
<p>Writers want people to talk after reading their writing. Not simply about style—though that is interesting and helpful—but thoughts more spiritual in nature. What did the reader think about after reading? It doesn’t even have to be related. Just say what you think about… because people rarely say what they think about.</p>

  </div>
  
    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
  
</div>
]]></summary>
</entry>
<entry>
    <title>Understanding between sexual cultures</title>
    <link href="http://holdenlee.github.io/Understanding%20between%20sexual%20cultures.html" />
    <id>http://holdenlee.github.io/Understanding%20between%20sexual%20cultures.html</id>
    <published>2017-08-13T00:00:00Z</published>
    <updated>2017-08-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">

  <div id="content">
    <div class="page header">
      <h1> Understanding between sexual cultures </h1>
    </div>
    
    
    <div class="info">
      
       
        <p>Posted: 2017-08-13 
          , Modified: 2017-08-13 
	</p>
      
       <p>Tags: <a href="/tags/culture.html">culture</a>, <a href="/tags/LGBT.html">LGBT</a>, <a href="/tags/sexuality.html">sexuality</a>, <a href="/tags/understanding.html">understanding</a></p> 
       <p>Parent: <a href="/Views.html">Views</a></p> 
	   <p>Children: </p> 
    </div>
    
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>Update: <a href="http://rationallyspeakingpodcast.org/show/rs-187-jason-weeden-on-do-people-vote-based-on-self-interest.html">Jason Weeden</a> gave an interesting interview discussing “ring-bearers” and “free-wheelers”.</p>
<p>I feel that a lot can be solved if people have the right attitude (meta-moral sense?). Trying to understand each other. Rather than having a foundational goal to draw a dividing line between oneself and others (it’s amazing how many actions can be traced back to that “tribal” motivation), seek to understand each other and both better your own life and other people’s. I think if you replace these foundational goals, the justification for certain actions melts away.</p>
<p>A lot of it comes back to what Karen Armstrong said about jihadists. If people feel their belief system, their values, their community is being threatened, they will go on the offensive. It’s human nature. Someone has to break the cycle, and try to understand the other side even as the other side is throwing words, or worse, sticks and stones, at you.</p>
<p>One place where this is especially true is in sexuality. On the one side are conservative people (sex after marriage, man and woman, etc.). On another are LGBTP people (P=poly), or people who promote a more open sexual culture (a la Stranger in a Strange Land). And there are people who participate in the “casual hookup culture.” Of course, there are many shades of gray in between.</p>
<p>So let’s look at the web of threats. LGBTP people are threatened by the conservative people—it’s hard to talk with someone who thinks it’s a moral sin (go to hell) for you to have the sexual identity that you have! Conservative people are threatened by the increasing number of people who participate in the “casual hookup culture.” It’s been flipped from 100 years ago, that believing in sex after marriage can actually make you part of the minority, and disparagingly called a “prude.” They feel threatened by sexual jokes that people make to them, and lewd behavior in public. (Brave New World shows this by taking it to the extreme: what if you are the ONLY person who believes in committed monogamy?) (And it’s complicated: people will claim they have the freedom to do what they want, which is true, but with freedom comes the responsibility to use the freedom wisely. Just because you <em>can</em> eat steak in front of a vegetarian, doesn’t mean you should.) The people who participate in casual hookup culture feel threatened by the conservatives: this is the kind of prudishness that they’re trying to escape. The conservatives feel threatened by the LGBTP people because they go against religious teachings. This last link is flawed though—if these conservative people remove their “tribal” motivation and allow their opinion to be changed, then it’s pretty clear that what they are rebelling against is the loss of family values—where freed from the Bible’s word, family should have a more abstract interpretation as a cohesive, symbiotic community unit—and then they should <strong>look for evidence</strong> for or against LGBTP relationships meeting that criteria (and the evidence is overwhelming for the fact that they can meet that criteria).</p>
<p>I think we need to draw the line between what a person believes in, and what’s universal. What’s universal here is wanting to be happy, have some kind of stability in life, having good relationships with other people, protecting from disease (which is actually very important here—and a fact that has been disguised. rather than standing on its own as a goal, it’s been cited as evidence of immorality of sex. The causality is screwed up here: immorality does not cause disease!). Trying to tack more than this starts to skew this universal picture towards one’s own view. There’s the kind of person who wants to follow the traditional path of marriage, and the kind who will have flings with a lot of people. (The problem with SiaSL is that it seemed to suggest that the second option is strictly better for every person, which is untrue.) Each person has their own personal truths, but some truths are better than others. The best that these different groups can do is not to impose their worldview on each other, but to explain to people what is it that their way of life offers, to try and talk to people about the link between the universal things that they want (see above) and the sexual life that they choose. Imagine them next to each other in an activities fair. The conservative group talks about how abstinence helps one develop a strong moral fiber in the sense of “delayed gratification” being a general helpful quality to nurture in one’s life, attach more weight and meaning to one’s actions, etc. (I personally believe in sex after marriage <em>for myself</em>, and these are the terms I think in, not religious commandments.) The liberal group talks about how sexuality can be an important part of your identity as a human being, how it can be a pleasurable and healthy part of your life, etc. And what I mean by “some truths are better than others,” is that anyone can declare that they’re doing is “right, you got a problem with that?” but if you haven’t thought through these issues, and you leave behind a trail of broken hearts and find your life empty, then chances are that you should have thought things over more. I find that often the most mature views on sexuality come from the LGBTP community, just because they have had to grapple with these issues while most other people just shove them under the rug (ex. poly people talk about things like jealousy and commitment because they have to, while mono people can often have trouble even starting the conversation on these topics).</p>

  </div>
  
    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
  
</div>
]]></summary>
</entry>

</feed>
